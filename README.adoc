= Serverless and Pipelines
:experimental:
:git-repo: https://github.com/kameshsampath/minikube-helpers

== Pre-requisites
* https://github.com/mikefarah/yq/
* https://github.com/ahmetb/kubectx/blob/master/kubens[kubens]
* https://github.com/tektoncd/cli[tkn]

== Minikube 

[source,bash]
----
minikube start \
 --container-runtime=cri-o \
 --insecure-registry="10.0.0.0/24" \
 --memory=8192 --cpus=6 --disk-size=50G \ #<1>
 --extra-config=apiserver.enable-admission-plugins="LimitRanger,NamespaceExists,NamespaceLifecycle,ResourceQuota,ServiceAccount,DefaultStorageClass,MutatingAdmissionWebhook"
----
<1> By default minikube uses 10GB and 6cpus, if you have enough capacity then you can skip this setting

== Enable registry addon 

IMPORTANT: Only for minikube 

[source,bash]
----
minikube addons enable registry
----

Wait for the registry pod to be up 

[source,bash]
----
kubectl -n kube-system get pods -w 
----

NOTE: You can terminate the command with kbd:[CTRL+c]

Clone the minikube-helpers repo

[source,bash,subs="attribute+,macros+"]
----
git clone {git-repo}
cd minikube-helpers
----

== Configure registry aliases

To be able to push and pull images from internal registry we need to make the registry entry in minikube node's **hosts** file and make them resolvable via **coredns**. 

=== Add entries to host file

All the registry aliases are configured using the configmap `registry-aliases-config.yaml`, we need to create the configmap in `kube-system` namespace:

[source,bash]
----
git clone https://github.com/kameshsampath/minikube-helpers
cd registry
kubectl apply -n kube-system -f registry-aliases-config.yaml
----

Once the ConfigMap has been created we can run the dameonset `node-etc-hosts-update.yaml` to make in add entries to the minikube node's `/etc/hosts` file with all aliases pointing to internal registrys' __CLUSTER_IP__

[source,bash]
----
kubectl apply -n kube-system -f node-etc-hosts-update.yaml
----

[NOTE]
====
 * Wait for the daemonset to be running before proceeding to next step, the status of the daemonset can be viewed via `kubectl get pods -n kube-system -w`, you can do kbd:[CTRL+C] to end the watch.
 * The daemonset may take few minutes to run and complete.
====

You can check the mikikube vm's `/etc/hosts` file for the registry aliases entries:

[source,bash]
----
$ minikube ssh -- sudo cat /etc/hosts
127.0.0.1       localhost
127.0.1.1 demo
10.111.151.121  dev.local
10.111.151.121  example.com
----
The above output shows that the daemonset has added the `registryAliases` from the ConfigMap pointing to the internal registry's __CLUSTER-IP__.

=== Update coredns

Update the Kubernetes' coredns to have rewrite rules for aliases.

[source,bash]
----
./patch-coredns.sh
----

A successful patch will have the coredns configmap updated like:

[source,yaml]
----
apiVersion: v1
data:
  Corefile: |-
    .:53 {
        errors
        health
        rewrite name dev.local registry.kube-system.svc.cluster.local
        rewrite name example.com registry.kube-system.svc.cluster.local
        kubernetes cluster.local in-addr.arpa ip6.arpa {
           pods insecure
           upstream
           fallthrough in-addr.arpa ip6.arpa
        }
        prometheus :9153
        proxy . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }
kind: ConfigMap
metadata:
  name: coredns
----

To verify it run the following command:

[source,bash]
----
kubectl get cm -n kube-system coredns -o yaml
----

Once you have successfully patched you can now push and pull from the registry using suffix `dev.local`, `example.com`

== Install Knative Serving 

[source,bash]
----
curl -L  https://raw.githubusercontent.com/knative/serving/release-0.6/third_party/istio-1.1.3/istio-lean.yaml \
  | sed 's/LoadBalancer/NodePort/' \
  | kubectl apply --filename -
----

Wait for the Istio Pods to come up 

NOTE: You can terminate the command with kbd:[CTRL+c]

[source,bash]
----
kubectl apply --selector knative.dev/crd-install=true \
--filename https://github.com/knative/serving/releases/download/v0.6.0/serving.yaml \
--filename https://github.com/knative/serving/releases/download/v0.6.0/serving.yaml --selector networking.knative.dev/certificate-provider!=cert-manager 
----

Wait for the  Knative Serving Pods to come up 

[source,bash]
----
kubectl get pods --namespace knative-serving -w 
----

NOTE: You can terminate the command with kbd:[CTRL+c]

== Install Tekton Pipelines

[source,bash]
----
kubectl apply --filename https://storage.googleapis.com/tekton-releases/latest/release.yaml
----

Wait for the Tekton Pipelines Pods to come up 

[source,bash]
----
kubectl get pods --namespace tekton-pipelines -w 
----

NOTE: You can terminate the command with kbd:[CTRL+c]

== Configure Pipelines

As the build need to be run with service account that needs permissions to create resources, a new service account 'build-robot' needs to be created with required permissions.

Download the demo sources and lets call the folder as `$PROJECT_HOME`:

[source,bash]
----
git clone https://redhat-developer-demos/quarkus-pipeline-demo &&\
cd quarkus-pipeline-demo &&\
export PROJECT_HOME=`pwd`
----

IMPORTANT: All the objects will be created in the namespace called `demos`, if you wish to change it please edit the file build/build-roles.yaml and update the namespace name.

[source,bash]
----
kubectl apply -f $PROJECT_HOME/build/build-roles.yaml
----

Change to the `demos` namespace 

[source,bash]
----
kubens demos
----

The build uses resources called https://github.com/tektoncd/pipeline/blob/master/docs/resources.md[PipelineResource] that helps to configure the git repo url, the final container image name etc., 

Let's create the resources

[source,bash]
----
kubectl apply -f $PROJECT_HOME/build/build-resources.yaml
----

The Pipeline consists of multiple tasks that needs to be executed in order.

Let's create the pipeline tasks

[source,bash]
----
kubectl apply --recursive -f $PROJECT_HOME/build/tasks
----

You can use the command `tkn task list`  to list the created tasks. The command above should show the following tasks:

```
NAME                     AGE
greeter-image-from-git   22 seconds ago
kubectl-task             22 seconds ago
```

Let's create the pipeline that uses the tasks create in previous step

[source,bash]
----
kubectl apply --recursive -f $PROJECT_HOME/build/pipelines
----

You can use the command `tkn pipeline list`  to list the created tasks. The command above should show the following pipeline:

```
NAME                      AGE             LAST RUN   STARTED   DURATION   STATUS
greeter-pipeline-jvm      5 seconds ago   ---        ---       ---        ---
greeter-pipeline-native   5 seconds ago   ---        ---       ---        ---
```

To make the pipeline run, we need to create the  https://github.com/tektoncd/pipeline/blob/master/docs/pipelineruns.md[PipelineRun]

Let's create the pipelinerun that uses the one of pipelines e.g. **greeter-pipeline-jvm** created in previous step

[source,bash]
----
kubectl apply --recursive -f $PROJECT_HOME/build/pipelinerun/greeter-pipeline-run.yaml
----

You can use the command `tkn pipelinerun list`  to list the created tasks. The command above should show the following pipeline:

```
NAME                   STARTED         DURATION   STATUS
greeter-pipeline-run   8 seconds ago   ---        Running
```

You can view the logs of the pipeline run using the command `tkn pipelinerun logs -f -a greeter-pipeline-run`

NOTE: The very first pipeline run may take sometime, as the builder images needs to be downloaded and the maven cache needs to be warmed

[TIP]
====
If you have a local maven repo manager like Nexus then you can configure the pipeline to use it via the param `mavenMirrorUrl`
e.g.
[source,yaml]
----
  params:
    - name: mavenMirrorUrl
      value: http://192.168.99.1:8081/nexus/content/groups/public #<1>
----
<1> Assuming your nexus repository is running in http://192.168.99.1:8081
====

A successful pipeline run will deploy an application called "greeter" and a correponding service called `greeter-service`, you can view them using the following commands:

[source,bash]
----
kubectl get -n demos deployments
kubectl get -n demos services
----